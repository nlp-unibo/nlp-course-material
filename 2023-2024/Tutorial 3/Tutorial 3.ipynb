{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3adf1fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 3\n",
    "\n",
    "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
    "\n",
    "**Keywords**: Transformers, Huggingface, Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30acbc3",
   "metadata": {
    "id": "m3wzWLL-LiKd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "* Eleonora Mancini -> e.mancini@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44dadc7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART 0 ($\\sim$5 mins)\n",
    "*   Downloading a **dataset**.\n",
    "*   Encoding a a **dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f10c45",
   "metadata": {
    "id": "gl48Am5trp3Y",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART I ($\\sim$30 mins)\n",
    "\n",
    "*   Text encoding with transformers.\n",
    "*   Model definition.\n",
    "*   Model training and evaluation with huggingface APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1762696",
   "metadata": {
    "id": "D4anSmM4rp3Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PART II ($\\sim$30 mins)\n",
    "\n",
    "*   Prompting 101\n",
    "*   Sentiment analysis with prompting\n",
    "*   LangChain intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86860b11",
   "metadata": {
    "id": "c4-E45fvrp3Z",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "First of all, we need to import some useful packages that we will use during this hands-on session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2305467f",
   "metadata": {
    "id": "rUXZLYya69wc",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# system packages\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import urllib\n",
    "import tarfile\n",
    "import sys\n",
    "\n",
    "# data and numerical management packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# useful during debugging (progress bars)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# typing\n",
    "from typing import List, Callable, Dict, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9ac9d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0eeca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets                          2.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7301b767",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch==1.13.0+cu116 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (1.13.0+cu116)\n",
      "Requirement already satisfied: typing-extensions in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from torch==1.13.0+cu116) (4.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers==4.18.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (4.18.0)\n",
      "Requirement already satisfied: filelock in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (2022.4.24)\n",
      "Requirement already satisfied: requests in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (2.27.1)\n",
      "Requirement already satisfied: sacremoses in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from transformers==4.18.0) (6.7.0)\n",
      "Requirement already satisfied: fsspec in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.18.0) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from importlib-metadata->transformers==4.18.0) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests->transformers==4.18.0) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests->transformers==4.18.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests->transformers==4.18.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests->transformers==4.18.0) (3.3)\n",
      "Requirement already satisfied: six in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\n",
      "Requirement already satisfied: click in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets==2.13.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (2.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (4.64.0)\n",
      "Requirement already satisfied: xxhash in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets==2.13.2) (6.7.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets==2.13.2) (4.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.2) (3.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from packaging->datasets==2.13.2) (3.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.13.2) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.13.2) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->datasets==2.13.2) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from importlib-metadata->datasets==2.13.2) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from pandas->datasets==2.13.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from pandas->datasets==2.13.2) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets==2.13.2) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: accelerate in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from accelerate) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from accelerate) (5.9.1)\n",
      "Requirement already satisfied: pyyaml in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from accelerate) (1.13.0+cu116)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from packaging>=20.0->accelerate) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from torch>=1.6.0->accelerate) (4.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (2.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (1.21.6)\n",
      "Requirement already satisfied: dill in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (4.64.0)\n",
      "Requirement already satisfied: xxhash in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (2023.1.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (21.3)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from evaluate) (6.7.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: aiohttp in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from packaging->evaluate) (3.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.13.0+cu116\n",
    "!pip install transformers==4.18.0\n",
    "!pip install datasets==2.13.2\n",
    "!pip install accelerate -U\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85a3743",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 2560, 'height': 1440, 'scroll': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 2560,\n",
    "        'height': 1440,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e6309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  6 14:33:24 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:0B:00.0  On |                  N/A |\r\n",
      "| 30%   33C    P8    25W / 320W |    659MiB / 10240MiB |     32%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1211      G   /usr/lib/xorg/Xorg                354MiB |\r\n",
      "|    0   N/A  N/A      2533      G   /usr/bin/gnome-shell               94MiB |\r\n",
      "|    0   N/A  N/A      3882      G   ...892643279696694844,262144      204MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef8f7c0",
   "metadata": {
    "id": "qImKj2Mu7LCX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use the IMDB dataset first introduced in tutorial 1.\n",
    "\n",
    "* [**Stats**] A dataset of 50k sentences used for sentiment analysis: 25k with positive sentiment, 25k with negative one.\n",
    "* [**Sentiment**] We consider sentiment labels for classification.\n",
    "\n",
    "We start by **downloading** the dataset and **extract** it to a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268c2b55",
   "metadata": {
    "id": "NSvqBcKJ7iTY",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(download_path: Path, url: str):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=download_path, reporthook=t.update_to)\n",
    "\n",
    "        \n",
    "def download_dataset(download_path: Path, url: str):\n",
    "    print(\"Downloading dataset...\")\n",
    "    download_url(url=url, download_path=download_path)\n",
    "    print(\"Download complete!\")\n",
    "\n",
    "def extract_dataset(download_path: Path, extract_path: Path):\n",
    "    print(\"Extracting dataset... (it may take a while...)\")\n",
    "    with tarfile.open(download_path) as loaded_tar:\n",
    "        loaded_tar.extractall(extract_path)\n",
    "    print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d62435",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current work directory: /home/frgg/Repositories/nlp-course-material/2023-2024/Tutorial 3\n"
     ]
    }
   ],
   "source": [
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset_name = \"aclImdb\"\n",
    "\n",
    "print(f\"Current work directory: {Path.cwd()}\")\n",
    "dataset_folder = Path.cwd().joinpath(\"Datasets\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    dataset_folder.mkdir(parents=True)\n",
    "\n",
    "dataset_tar_path = dataset_folder.joinpath(\"Movies.tar.gz\")\n",
    "dataset_path = dataset_folder.joinpath(dataset_name)\n",
    "\n",
    "if not dataset_tar_path.exists():\n",
    "    download_dataset(dataset_tar_path, url)\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    extract_dataset(dataset_tar_path, dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdbb37a",
   "metadata": {
    "id": "pv3NW1SNrp3a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Data Format\n",
    "\n",
    "Just like in the first assignment, we need a **high level view** of the dataset that is helpful to our needs. \n",
    "\n",
    "We encode the dataset into a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9adf0a63",
   "metadata": {
    "id": "P05YfYCe7qCj",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataframe_rows = []\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        folder = dataset_folder.joinpath(dataset_name, split, sentiment)\n",
    "        for file_path in folder.glob('*.txt'):            \n",
    "            with file_path.open(mode='r', encoding='utf-8') as text_file:\n",
    "                text = text_file.read()\n",
    "                score = file_path.stem.split(\"_\")[1]\n",
    "                score = int(score)\n",
    "                file_id = file_path.stem.split(\"_\")[0]\n",
    "\n",
    "                num_sentiment = 1 if sentiment == 'pos' else 0\n",
    "\n",
    "                dataframe_row = {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"score\": score,\n",
    "                    \"sentiment\": num_sentiment,\n",
    "                    \"split\": split,\n",
    "                    \"text\": text\n",
    "                }\n",
    "\n",
    "                dataframe_rows.append(dataframe_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbec9321",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "folder = Path.cwd().joinpath(\"Datasets\", \"Dataframes\", dataset_name)\n",
    "if not folder.exists():\n",
    "    folder.mkdir(parents=True)\n",
    "\n",
    "# transform the list of rows in a proper dataframe\n",
    "df = pd.DataFrame(dataframe_rows)\n",
    "df = df[[\"file_id\", \n",
    "         \"score\",\n",
    "         \"sentiment\",\n",
    "         \"split\",\n",
    "         \"text\"]\n",
    "       ]\n",
    "df_path = folder.with_name(dataset_name + \".pkl\")\n",
    "df.to_pickle(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a185f8",
   "metadata": {
    "id": "Bjf3k-qVrp3b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PART I\n",
    "\n",
    "*   Text encoding with Transformers.\n",
    "*   Model definition.\n",
    "*   Model training and evaluation with huggingface APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a51f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Text encoding with Transformers.\n",
    "\n",
    "In tutorial 1, we have seen how to define standard machine learning models to address sentiment classification.\n",
    "\n",
    "However, we know that Transformer-based models are one of the strongest baselines when assessing a task or benchmarking on a novel corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33067d25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before defining our transformer-based classifier, we need to encode text inputs into numerical format.\n",
    "\n",
    "As in Tutorial 1, we are going to **tokenize** input texts to perform token indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f720fda",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 Encoding the dataset\n",
    "\n",
    "First, we are going to use ``datasets`` library to encode our dataset into a handy wrapper for computational speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e20f06bc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Slicing for showcasing purposes only!\n",
    "train_df = df.loc[df['split'] == \"train\"].sample(frac=1.0)[:5000]\n",
    "test_df = df.loc[df['split'] == \"test\"].sample(frac=1.0)[:1000]\n",
    "\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "test_data = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462b9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's inspect the newly defined `Dataset` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf57dd1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_id', 'score', 'sentiment', 'split', 'text', '__index_level_0__'],\n",
      "    num_rows: 5000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_id', 'score', 'sentiment', 'split', 'text', '__index_level_0__'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a46d5a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2 Tokenization\n",
    "\n",
    "Transformers typically use [SentencePiece tokenizer](https://github.com/google/sentencepiece) to perform sub-word level tokenization.\n",
    "\n",
    "In particular, the `transformers` library offers the `AutoTokenizer` class to quickly retrieve our chosen transformer's ad-hoc tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44595edb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_card = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec8c600",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `model_card` variable defines the *path* where to look for our pre-trained model.\n",
    "\n",
    "You can check [huggingface's hub](https://huggingface.co/models) model hub to pick the model card according to your preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce3faf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We proceed on tokenizing movie reviews text with our tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22969ad0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_text(texts):\n",
    "    return tokenizer(texts['text'], truncation=True)\n",
    "\n",
    "train_data = train_data.map(preprocess_text, batched=True)\n",
    "test_data = test_data.map(preprocess_text, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da82c94",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's inspect the preprocess `Dataset` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d6b460",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file_id', 'score', 'sentiment', 'split', 'text', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 5000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['file_id', 'score', 'sentiment', 'split', 'text', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1729211",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2630, 10608, 2003, 2941, 3855, 1999, 1996, 2143, 2021, 2025, 1999, 2151, 2126, 2008, 3084, 2151, 2825, 3168, 1012, 2012, 2028, 2391, 1010, 2070, 4268, 2024, 13071, 27046, 1996, 6748, 3798, 1010, 11131, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2027, 4088, 2000, 6848, 2054, 2027, 1005, 2222, 2424, 2091, 2045, 1998, 2028, 1997, 2068, 1006, 1037, 2611, 1007, 2758, 2016, 29475, 2027, 1005, 2222, 2424, 1037, 2630, 10608, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2748, 1010, 2008, 2015, 2009, 1012, 6135, 4297, 5644, 2063, 15417, 4818, 2000, 1996, 2466, 1010, 1996, 2069, 6517, 4434, 2000, 1996, 2516, 1010, 1998, 2053, 2801, 2339, 2016, 2052, 6814, 2016, 1005, 1040, 2424, 1037, 2630, 10608, 1999, 1037, 2902, 1005, 1055, 8102, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1045, 1005, 1049, 10339, 2005, 2383, 4622, 2009, 2021, 8307, 2018, 2000, 3342, 1045, 6814, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['input_ids'][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f9324da",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['attention_mask'][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cbe39b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can perform some quick 'sanity check' to evaluate the tokenization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d7c878d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue monkey is actually mentioned in the film but not in any way that makes any possible sense. At one point,some kids are wandering thru the deeper levels, exploring. <br /><br />They begin to discuss what they'll find down there and one of them (a girl) says she bets they'll find a blue monkey.<br /><br />Yes, thats it. Totally inconsequential to the story, the only sad connection to the title, and no idea why she would suppose she'd find a blue monkey in a hospital's basement.<br /><br />I'm embarrassed for having remembered it but somebody had to remember I suppose!\n",
      "\n",
      "\n",
      "[CLS] blue monkey is actually mentioned in the film but not in any way that makes any possible sense. at one point, some kids are wandering thru the deeper levels, exploring. < br / > < br / > they begin to discuss what they'll find down there and one of them ( a girl ) says she bets they'll find a blue monkey. < br / > < br / > yes, thats it. totally inconsequential to the story, the only sad connection to the title, and no idea why she would suppose she'd find a blue monkey in a hospital's basement. < br / > < br / > i'm embarrassed for having remembered it but somebody had to remember i suppose! [SEP]\n"
     ]
    }
   ],
   "source": [
    "original_text = train_data['text'][50]\n",
    "decoded_text = tokenizer.decode(train_data['input_ids'][50])\n",
    "\n",
    "print(original_text)\n",
    "print()\n",
    "print()\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650431ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.3 Vocabulary\n",
    "\n",
    "We **do not** necessarily need to build a vocabulary since transformers already come with their own! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863ee66",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**However**, it is still possible to add new tokens to the vocabulary to adapt the model to the given use case.\n",
    "\n",
    "```\n",
    "tokenizer.add_tokens(new_tokens=new_tokens)\n",
    "```\n",
    "\n",
    "The transformer vocabulary will update its **unusued** vocabulary indexes with newly provided tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b0c55",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.4 Special tokens\n",
    "\n",
    "**Pay attention** to used special tokens and their corresponding token ids.\n",
    "\n",
    "Each transformer models has its own special tokens ([CLS], [SEP], [PAD], [EOS], etc...).\n",
    "\n",
    "Thus, the same special token may be mapped to different token ids in distinct transformer models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e203e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.5 Text cleaning\n",
    "\n",
    "We didn't perform any kind of text cleaning before performing text encoding.\n",
    "\n",
    "This is usually because transformer tokenizers **have their own text cleaning process** to perform tokenization and models **may be sensitive** to custom operations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc77cc96",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['couldn', \"'\", 't']\n"
     ]
    }
   ],
   "source": [
    "example_text = \"couldn't\"\n",
    "encoded_example = tokenizer.encode_plus(example_text, add_special_tokens=False)\n",
    "print(encoded_example.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da65da5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'one', 'point', ',', 'some', 'kids', 'are', 'wandering', 'through', 'the', 'deeper', 'levels', ',', 'exploring', '.']\n"
     ]
    }
   ],
   "source": [
    "example_text = \"At one point,some kids are wandering through the deeper levels, exploring.\"\n",
    "encoded_example = tokenizer.encode_plus(example_text, add_special_tokens=False)\n",
    "print(encoded_example.tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fbc80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "`bert-base-uncased` is trained with text in lower format.\n",
    "\n",
    "**Check model cards** on huggingface to know more about the models you use and inspect their text encoding pipeline to understand how they behave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df975a08",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Homework ðŸ“–\n",
    "\n",
    "Experiment with different model cards.\n",
    "\n",
    "Experiment with text cleaning and evaluate its impact on classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331dd42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Model definition\n",
    "\n",
    "We are now ready to define our transformer-based classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf143c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 Data Formatting\n",
    "\n",
    "We first need to format input data to be fed as mini-batches in a training/evaluation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "955dca33",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba03005b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The ``DataCollatorWithPadding`` receives a batch of\n",
    "\n",
    "```\n",
    "(input_ids, attention_mask, token_type_ids, label)\n",
    "```\n",
    "\n",
    "tuples and **dynamically pads** ``input_ids``, ``attention_mask`` and ``token_type_ids`` to maximum sequence in the batch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28deb2da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively, this operation saves a lot of memory compared to padding to global maximum sequence, while it introduces a reasonable computational overhead.\n",
    "\n",
    "### Note\n",
    "\n",
    "The above example is just one way out of many to perform dynamic batch padding: it really depends on which data structures you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93106b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 Model definition\n",
    "\n",
    "Defining a transformer-based model with huggingface is pretty straightforward!\n",
    "\n",
    "Since we are dealing with text classification, we can use off-the-shelf `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a23fd54",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_card,\n",
    "                                                           num_labels=2,\n",
    "                                                           id2label={0: 'NEG', 1: 'POS'},\n",
    "                                                           label2id={'NEG': 0, 'POS': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cacb5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's first check the loaded model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9474b446",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73ae7c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**That's it!**\n",
    "\n",
    "That's the simplicity of huggingface's APIs.\n",
    "\n",
    "The model is ready to use for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7dff5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3 Custom architectures\n",
    "\n",
    "There are plenty of pre-defined model architectures $\\rightarrow$ [auto classes](https://huggingface.co/docs/transformers/model_doc/auto)\n",
    "\n",
    "In more complex scenarios, we may want to define a custom architecture where the pre-trained model is part of it.\n",
    "\n",
    "In these cases, the way you do it strongly depends on the underlying neural library.\n",
    "\n",
    "However, there exist several high-level APIs depending on your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79825da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3. Model training and evaluation\n",
    "\n",
    "We are now ready to define the training and evaluation procedures to test our model on the IMDB dataset.\n",
    "\n",
    "In particular, we are going to use ``Trainer`` APIs to efficiently perform training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d60ece",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Metrics\n",
    "\n",
    "First, we define classification metrics for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c352438",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(output_info):\n",
    "    predictions, labels = output_info\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    f1 = f1_score(y_pred=predictions, y_true=labels, average='macro')\n",
    "    acc = accuracy_score(y_pred=predictions, y_true=labels)\n",
    "    return {'f1': f1, 'acc': acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf404bc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Hugginface's metrics\n",
    "\n",
    "Huggingface's offers the **Evaluate** package that contains several evaluation metrics (e.g., accuracy, f1, squad-f1, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ffabd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Training Arguments\n",
    "\n",
    "The ``Trainer`` object can be extensively customized.\n",
    "\n",
    "Feel free to check the [documentation](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) on training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f569e08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60778a943ebf45e89482df9786bffe8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6803e7db6b934fd7b830a9d18d00f4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "acc_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(output_info):\n",
    "    predictions, labels = output_info\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    return {**f1, **acc}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba742520",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We first rename the `sentiment` column to `label` as the default input to `AutoModelForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "632180d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.rename_column('sentiment', 'label')\n",
    "test_data = test_data.rename_column('sentiment', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0c66bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_dir\",                 # where to save model\n",
    "    learning_rate=2e-5,                   \n",
    "    per_device_train_batch_size=8,         # accelerate defines distributed training\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",           # when to report evaluation metrics/losses\n",
    "    save_strategy=\"epoch\",                 # when to save checkpoint\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none'                       # disabling wandb (default)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c3afb0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc91d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training schema with collator\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/collator.png\" alt=\"collator\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75174013",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: score, split, file_id, __index_level_0__, text. If score, split, file_id, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/frgg/custom_envs/deasy_env/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 5000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 03:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.359200</td>\n",
       "      <td>0.253561</td>\n",
       "      <td>0.899994</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.312255</td>\n",
       "      <td>0.916963</td>\n",
       "      <td>0.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146800</td>\n",
       "      <td>0.353221</td>\n",
       "      <td>0.922870</td>\n",
       "      <td>0.923000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: score, split, file_id, __index_level_0__, text. If score, split, file_id, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_dir/checkpoint-625\n",
      "Configuration saved in test_dir/checkpoint-625/config.json\n",
      "Model weights saved in test_dir/checkpoint-625/pytorch_model.bin\n",
      "tokenizer config file saved in test_dir/checkpoint-625/tokenizer_config.json\n",
      "Special tokens file saved in test_dir/checkpoint-625/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: score, split, file_id, __index_level_0__, text. If score, split, file_id, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_dir/checkpoint-1250\n",
      "Configuration saved in test_dir/checkpoint-1250/config.json\n",
      "Model weights saved in test_dir/checkpoint-1250/pytorch_model.bin\n",
      "tokenizer config file saved in test_dir/checkpoint-1250/tokenizer_config.json\n",
      "Special tokens file saved in test_dir/checkpoint-1250/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: score, split, file_id, __index_level_0__, text. If score, split, file_id, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_dir/checkpoint-1875\n",
      "Configuration saved in test_dir/checkpoint-1875/config.json\n",
      "Model weights saved in test_dir/checkpoint-1875/pytorch_model.bin\n",
      "tokenizer config file saved in test_dir/checkpoint-1875/tokenizer_config.json\n",
      "Special tokens file saved in test_dir/checkpoint-1875/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from test_dir/checkpoint-625 (score: 0.2535613775253296).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1875, training_loss=0.21550222981770834, metrics={'train_runtime': 230.3159, 'train_samples_per_second': 65.128, 'train_steps_per_second': 8.141, 'total_flos': 1878284222786880.0, 'train_loss': 0.21550222981770834, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7904e1d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3 Evaluation\n",
    "\n",
    "We now evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bed901f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: score, split, file_id, __index_level_0__, text. If score, split, file_id, __index_level_0__, text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "test_prediction_info = trainer.predict(test_data)\n",
    "test_predictions, test_labels = test_prediction_info.predictions, test_prediction_info.label_ids\n",
    "\n",
    "print(test_predictions.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b09d55",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.8999935995903738, 'accuracy': 0.9}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = compute_metrics([test_predictions, test_labels])\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ee6e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Some cleaning before PART II\n",
    "\n",
    "Let's clean the memory and GPU before switching to instruction-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6898778a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "del trainer\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5c57b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PART II\n",
    "\n",
    "*   Prompting 101\n",
    "*   Sentiment analysis with prompting\n",
    "*   LangChain intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbe5ee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Prompting 101\n",
    "\n",
    "Prompting is a technique used to adapt a model to a variety of tasks without requiring fine-tuning.\n",
    "\n",
    "```\n",
    "Classify the text into neutral, negative or positive.\n",
    "Text: {text}\n",
    "Sentiment:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088c2cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model receives the above input prompt and performs text classification via completion.\n",
    "\n",
    "```\n",
    "Classify the text into neutral, negative or positive.\n",
    "Text: {text}\n",
    "Sentiment: {label}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7d59b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In natural language, prompting is a very delicate process since natural language is **expressive**, **flexible**, and, **ambiguous**.\n",
    "\n",
    "A certain concept can be expressed in several ways:\n",
    "\n",
    "* These ways are semantically **equivalent**\n",
    "* May lead to **significant** model performance **drifts**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64565dc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.1 Sensitivity Factors\n",
    "\n",
    "There are two main factors to consider when performing prompt-based learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab35a56",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Prompt Engineering](https://huggingface.co/docs/transformers/main/tasks/prompting#basics-of-prompting)\n",
    "\n",
    "Eventually we have to iteratively find the best performing prompt.\n",
    "\n",
    "This can either done\n",
    "\n",
    "* Manually\n",
    "* Automatically (via an ad-hoc model).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395b2f34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [Generation hyper-parameters](https://huggingface.co/docs/transformers/main/generation_strategies#text-generation-strategies)\n",
    "\n",
    "Finding the optimal text generation strategy is a **critical point** for achieving satisfying performance.\n",
    "\n",
    "These strategies affects how the model iteratively selects tokens during generation to avoid phenomena like repetitions, rare words, coherence with input text, and style.\n",
    "\n",
    "* [Deterministic] Greedy $\\rightarrow$ the most preferred (i.e., highest likelihood) token wins\n",
    "* [Deterministic] Beam search\n",
    "* [Stochastic] Top-k sampling\n",
    "* [Stochastic] Nucleus sampling\n",
    "* [Contrastive search](https://huggingface.co/blog/introducing-csearch)  $\\leftarrow$ **recommended**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c7415",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1.2 Model types\n",
    "\n",
    "There are a lot of different large language models and it is quite easy to be confused.\n",
    "\n",
    "Essentially, we have:\n",
    "\n",
    "* **Base models** (either encoders or encode-decoders): very good at text completion.\n",
    "* **Chat-based models**: base models specifically fine-tuned to address instructions or to chat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48705b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "In Huggingface, the distinct is easily formatted as:\n",
    "\n",
    "* `llama2-7b`            $\\rightarrow$ base model\n",
    "* `llama2-7b-*-instruct`   $\\rightarrow$ chat-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b54eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 2. Sentiment analysis with prompting\n",
    "\n",
    "Let's consider our task once again to evaluate prompt-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed90648",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1 Model pipeline\n",
    "\n",
    "First, we have to define the model pipeline to digest input prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7999c149",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We choose the `model_card` to build our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce4a39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model_card = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b858be",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we build the corresponding tokenizer and text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b7eda",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
    "\n",
    "model_pipe = pipeline('text-generation',\n",
    "                       model=model_card,\n",
    "                       tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549d4350",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 Inference\n",
    "\n",
    "We are now ready to feed prompts to our model and evaluate its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96d66e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's start with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34acc8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Classify the text into negative or positive. \n",
    "Text: This movie is definitely one of my favorite movies of its kind. The interaction between respectable and morally strong characters is an ode to chivalry and the honor code amongst thieves and policemen.\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=10,\n",
    ")[0]\n",
    "\n",
    "print(sequences['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b2be3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we try with the whole test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a4c25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def prepend_prompt(example):\n",
    "    example['text'] = formatting_prompt.format(example['text'])\n",
    "    return example\n",
    "    \n",
    "\n",
    "formatting_prompt = \"\"\"Classify the text into negative or positive. \n",
    "Text: {0}\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "test_data = test_data.map(preprend_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad2477",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def parse_generation(text):\n",
    "    label = text.split('Sentiment:')[1].strip()\n",
    "    return 1 if label.casefold() == 'positive' else 0\n",
    "\n",
    "\n",
    "sequences = pipe(\n",
    "    test_data['text'],\n",
    "    max_new_tokens=10\n",
    ")\n",
    "\n",
    "predictions = [parse_generation(seq['generated_text']) for seq in sequences]\n",
    "\n",
    "metrics = compute_metrics([predictions, test_data['label']])\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01437d0e",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Add homework https://huggingface.co/docs/transformers/main/generation_strategies#assisted-decoding\n",
    "https://huggingface.co/docs/transformers/main/llm_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12d946",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3. Advanced Prompting\n",
    "\n",
    "There is no rule of thumb to perform well on prompting.\n",
    "\n",
    "Some may argue it is *art*, some others might say it is just *engineering*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2402b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, here are some **general recommendations**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c767e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Check **how** the pre-trained model you are using was trained!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfffbcd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Start **simple** and then refine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd63938",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Instructions at the **start/end** of the prompt $\\rightarrow$ based on how most attention layers work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5648a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Separate** input text from instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3bd38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Provide **clear description** of the task: no ambiguity, text format, style, language, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ce0df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Evaluate** the prompt on several models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc086cd4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Use advanced techniques: **few-shot prompting**, **Chain-of-thought (CoT)**, Least-to-Most (LtM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96edcd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Few-shot Prompting\n",
    "\n",
    "https://huggingface.co/docs/transformers/main/tasks/prompting#best-practices-of-llm-prompting\n",
    "https://huggingface.co/docs/transformers/custom_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c7ee5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.2 Chain-of-thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5115d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.3 Prompting vs Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61726a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06465328",
   "metadata": {
    "id": "UbzMCMfprp3m",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
